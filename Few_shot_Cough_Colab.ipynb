{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZDcZLnFZqEV"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75gtxDGnPpfc"
      },
      "source": [
        "### Mount GG Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjETRZ4zIYAM",
        "outputId": "ce4e8f30-b182-4e68-dd5e-0f0b0d3ab020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWMRTE2eOJnf",
        "outputId": "10a77350-d02d-4be6-de6c-b4946828c456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "/content\n",
            "mkdir: cannot create directory ‘drive’: File exists\n",
            "/content/drive\n",
            "mkdir: cannot create directory ‘MyDrive’: File exists\n",
            "/content\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUDog97k5dN2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive._mount('/content/drive')\n",
        "# 4/1AX4XfWh6cSbEp31EzgkRSzdskWTL0RAwt2USXPP63sqQhQipglmXG6bD31w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXki22Zxcy9J",
        "outputId": "aee1ae56-7220-438b-a761-4bc5c87a0097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/cough_detection/few-shot-fed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-WfOQWhc1Id"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/trananhdat/few-shot-ho.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwMfYJ3Ac4Sw",
        "outputId": "128a6325-e270-484a-86cf-533416fbb5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "few-shot-ho  few-shot-ho-master.zip  logs\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KvQ0rC5c7l8",
        "outputId": "5f7b6563-36ff-4852-859a-43710a53d3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t       figures\t  protonets.egg-info  results  setup.py\n",
            "fewshotspeech  protonets  requirements.txt    scripts\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho'\n",
        "os.chdir(path)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTUY3iwWdAZH",
        "outputId": "c75d756b-09e0-486f-87e6-67abe77afed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchnet in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.0.4)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.7/dist-packages (from torchnet->-r requirements.txt (line 2)) (0.1.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchnet->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 4)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet->-r requirements.txt (line 2)) (0.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet->-r requirements.txt (line 2)) (1.32)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet->-r requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet->-r requirements.txt (line 2)) (22.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.7/dist-packages (from jsonpatch->visdom->torchnet->-r requirements.txt (line 2)) (2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zApF9RikdCsb",
        "outputId": "eb30efad-646a-4bcc-f784-10f012f45844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "writing protonets.egg-info/PKG-INFO\n",
            "writing dependency_links to protonets.egg-info/dependency_links.txt\n",
            "writing requirements to protonets.egg-info/requires.txt\n",
            "writing top-level names to protonets.egg-info/top_level.txt\n",
            "writing manifest file 'protonets.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/protonets.egg-link (link to .)\n",
            "protonets 0.0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed/few-shot-ho\n",
            "Processing dependencies for protonets==0.0.1\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.11.0+cu113\n",
            "Best match: torch 1.11.0+cu113\n",
            "Adding torch 1.11.0+cu113 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for protonets==0.0.1\n"
          ]
        }
      ],
      "source": [
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0bCwdFNdFoL",
        "outputId": "38267acd-5b8a-41d6-c168-3a7004612909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download_prepare_data.py  speech_commands\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/data/'\n",
        "os.chdir(path)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKp7RpModJeB"
      },
      "outputs": [],
      "source": [
        "# !python download_prepare_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bE0G1jv-WCK"
      },
      "outputs": [],
      "source": [
        "# !cp -R /content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/* /content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/data/speech_commands/core/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeYVfID6rIuM"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# path = '/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/scripts/train/few_shot/fewshotspeech/'\n",
        "# os.chdir(path)\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhcGB-iCvbPS",
        "outputId": "4c33bbc3-627e-4001-b55a-d67b2a9058fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3.3.0 in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (0.0.53)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (0.1.96)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (0.8.1rc2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.0) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkPnbC_shXs2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBV2NvoivfCV",
        "outputId": "61d7b3df-3620-4ce0-c62e-a00428418a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download_prepare_data.py  speech_commands\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j9OLGfjvgnq",
        "outputId": "bf42f666-1016-4494-d2cd-330edbb52576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access 'train.sh': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod +x train.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkiZL8G3vjUS"
      },
      "source": [
        "# Fed FrameWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzAQf6hpvlny",
        "outputId": "a8906406-c9d6-44b7-b7b1-c1102e101db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyqP9YVnvp6I"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def args_parser():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # federated arguments (Notation for the arguments followed from paper)\n",
        "    parser.add_argument('--epochs', type=int, default=10,\n",
        "                        help=\"number of rounds of training\")\n",
        "    parser.add_argument('--num_users', type=int, default=5,\n",
        "                        help=\"number of users: K\")\n",
        "    parser.add_argument('--frac', type=float, default=0.1,\n",
        "                        help='the fraction of clients: C')\n",
        "    parser.add_argument('--local_ep', type=int, default=10,\n",
        "                        help=\"the number of local epochs: E\")\n",
        "    parser.add_argument('--local_bs', type=int, default=10,\n",
        "                        help=\"local batch size: B\")\n",
        "    parser.add_argument('--lr', type=float, default=0.01,\n",
        "                        help='learning rate')\n",
        "    parser.add_argument('--momentum', type=float, default=0.5,\n",
        "                        help='SGD momentum (default: 0.5)')\n",
        "\n",
        "    # model arguments\n",
        "    parser.add_argument('--model', type=str, default='mlp', help='model name')\n",
        "    parser.add_argument('--kernel_num', type=int, default=9,\n",
        "                        help='number of each kind of kernel')\n",
        "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
        "                        help='comma-separated kernel size to \\\n",
        "                        use for convolution')\n",
        "    parser.add_argument('--num_channels', type=int, default=1, help=\"number \\\n",
        "                        of channels of imgs\")\n",
        "    parser.add_argument('--norm', type=str, default='batch_norm',\n",
        "                        help=\"batch_norm, layer_norm, or None\")\n",
        "    parser.add_argument('--num_filters', type=int, default=32,\n",
        "                        help=\"number of filters for conv nets -- 32 for \\\n",
        "                        mini-imagenet, 64 for omiglot.\")\n",
        "    parser.add_argument('--max_pool', type=str, default='True',\n",
        "                        help=\"Whether use max pooling rather than \\\n",
        "                        strided convolutions\")\n",
        "\n",
        "    # other arguments\n",
        "    parser.add_argument('--dataset', type=str, default='mnist', help=\"name \\\n",
        "                        of dataset\")\n",
        "    parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
        "                        of classes\")\n",
        "    parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
        "                        to a specific GPU ID. Default set to use CPU.\")\n",
        "    parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
        "                        of optimizer\")\n",
        "    parser.add_argument('--iid', type=int, default=1,\n",
        "                        help='Default set to IID. Set to 0 for non-IID.')\n",
        "    parser.add_argument('--unequal', type=int, default=0,\n",
        "                        help='whether to use unequal data splits for  \\\n",
        "                        non-i.i.d setting (use 0 for equal splits)')\n",
        "    parser.add_argument('--stopping_rounds', type=int, default=10,\n",
        "                        help='rounds of early stopping')\n",
        "    parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
        "    parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
        "    args = parser.parse_args(args=['--model=cnn', '--dataset=cifar', '--gpu=0', '--iid=1', '--epochs=10'])\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzhcrWEnvrvN",
        "outputId": "1233ef29-ae07-45ff-ddc2-a8b995d180d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t       figures\t  protonets.egg-info  results  setup.py\n",
            "fewshotspeech  protonets  requirements.txt    scripts\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/'\n",
        "os.chdir(path)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-_QrIvjvwOn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class DatasetSplit(Dataset):\n",
        "    \"\"\"An abstract Dataset class wrapped around Pytorch Dataset class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.idxs = [int(i) for i in idxs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return torch.tensor(image), torch.tensor(label)\n",
        "\n",
        "\n",
        "class LocalUpdate(object):\n",
        "    def __init__(self, args, dataset, idxs, logger):\n",
        "        self.args = args\n",
        "        self.logger = logger\n",
        "        self.trainloader, self.validloader, self.testloader = self.train_val_test(\n",
        "            dataset, list(idxs))\n",
        "        self.device = 'cuda' if args.gpu else 'cpu'\n",
        "        # Default criterion set to NLL loss function\n",
        "        self.criterion = nn.NLLLoss().to(self.device)\n",
        "\n",
        "    def train_val_test(self, dataset, idxs):\n",
        "        \"\"\"\n",
        "        Returns train, validation and test dataloaders for a given dataset\n",
        "        and user indexes.\n",
        "        \"\"\"\n",
        "        # split indexes for train, validation, and test (80, 10, 10)\n",
        "        idxs_train = idxs[:int(0.8*len(idxs))]\n",
        "        idxs_val = idxs[int(0.8*len(idxs)):int(0.9*len(idxs))]\n",
        "        idxs_test = idxs[int(0.9*len(idxs)):]\n",
        "\n",
        "        trainloader = DataLoader(DatasetSplit(dataset, idxs_train),\n",
        "                                 batch_size=self.args.local_bs, shuffle=True)\n",
        "        validloader = DataLoader(DatasetSplit(dataset, idxs_val),\n",
        "                                 batch_size=int(len(idxs_val)/10), shuffle=False)\n",
        "        testloader = DataLoader(DatasetSplit(dataset, idxs_test),\n",
        "                                batch_size=int(len(idxs_test)/10), shuffle=False)\n",
        "        return trainloader, validloader, testloader\n",
        "\n",
        "    def update_weights(self, model, global_round):\n",
        "        # Set mode to train model\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "\n",
        "        # Set optimizer for the local updates\n",
        "        if self.args.optimizer == 'sgd':\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=self.args.lr,\n",
        "                                        momentum=0.5)\n",
        "        elif self.args.optimizer == 'adam':\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr,\n",
        "                                         weight_decay=1e-4)\n",
        "\n",
        "        for iter in range(self.args.local_ep):\n",
        "            batch_loss = []\n",
        "            for batch_idx, (images, labels) in enumerate(self.trainloader):\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                model.zero_grad()\n",
        "                log_probs = model(images)\n",
        "                loss = self.criterion(log_probs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if self.args.verbose and (batch_idx % 10 == 0):\n",
        "                    print('| Global Round : {} | Local Epoch : {} | [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                        global_round, iter, batch_idx * len(images),\n",
        "                        len(self.trainloader.dataset),\n",
        "                        100. * batch_idx / len(self.trainloader), loss.item()))\n",
        "                self.logger.add_scalar('loss', loss.item())\n",
        "                batch_loss.append(loss.item())\n",
        "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
        "\n",
        "        return model.state_dict(), sum(epoch_loss) / len(epoch_loss)\n",
        "\n",
        "    def inference(self, model):\n",
        "        \"\"\" Returns the inference accuracy and loss.\n",
        "        \"\"\"\n",
        "\n",
        "        model.eval()\n",
        "        loss, total, correct = 0.0, 0.0, 0.0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(self.testloader):\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "            # Inference\n",
        "            outputs = model(images)\n",
        "            batch_loss = self.criterion(outputs, labels)\n",
        "            loss += batch_loss.item()\n",
        "\n",
        "            # Prediction\n",
        "            _, pred_labels = torch.max(outputs, 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "            total += len(labels)\n",
        "\n",
        "        accuracy = correct/total\n",
        "        return accuracy, loss\n",
        "\n",
        "\n",
        "def test_inference(args, model, test_dataset):\n",
        "    \"\"\" Returns the test accuracy and loss.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    loss, total, correct = 0.0, 0.0, 0.0\n",
        "\n",
        "    device = 'cuda' if args.gpu else 'cpu'\n",
        "    criterion = nn.NLLLoss().to(device)\n",
        "    testloader = DataLoader(test_dataset, batch_size=128,\n",
        "                            shuffle=False)\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(testloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Inference\n",
        "        outputs = model(images)\n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        loss += batch_loss.item()\n",
        "\n",
        "        # Prediction\n",
        "        _, pred_labels = torch.max(outputs, 1)\n",
        "        pred_labels = pred_labels.view(-1)\n",
        "        correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "        total += len(labels)\n",
        "\n",
        "    accuracy = correct/total\n",
        "    return accuracy, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbd6PJnfv27r"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer_input = nn.Linear(dim_in, dim_hidden)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.layer_hidden = nn.Linear(dim_hidden, dim_out)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, x.shape[1]*x.shape[-2]*x.shape[-1])\n",
        "        x = self.layer_input(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_hidden(x)\n",
        "        return self.softmax(x)\n",
        "\n",
        "\n",
        "class CNNMnist(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNNMnist, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(args.num_channels, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, args.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "class CNNFashion_Mnist(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNNFashion_Mnist, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc = nn.Linear(7*7*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class CNNCifar(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNNCifar, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, args.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class modelC(nn.Module):\n",
        "    def __init__(self, input_size, n_classes=10, **kwargs):\n",
        "        super(AllConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, 96, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(96, 96, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(96, 96, 3, padding=1, stride=2)\n",
        "        self.conv4 = nn.Conv2d(96, 192, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(192, 192, 3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(192, 192, 3, padding=1, stride=2)\n",
        "        self.conv7 = nn.Conv2d(192, 192, 3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(192, 192, 1)\n",
        "\n",
        "        self.class_conv = nn.Conv2d(192, n_classes, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_drop = F.dropout(x, .2)\n",
        "        conv1_out = F.relu(self.conv1(x_drop))\n",
        "        conv2_out = F.relu(self.conv2(conv1_out))\n",
        "        conv3_out = F.relu(self.conv3(conv2_out))\n",
        "        conv3_out_drop = F.dropout(conv3_out, .5)\n",
        "        conv4_out = F.relu(self.conv4(conv3_out_drop))\n",
        "        conv5_out = F.relu(self.conv5(conv4_out))\n",
        "        conv6_out = F.relu(self.conv6(conv5_out))\n",
        "        conv6_out_drop = F.dropout(conv6_out, .5)\n",
        "        conv7_out = F.relu(self.conv7(conv6_out_drop))\n",
        "        conv8_out = F.relu(self.conv8(conv7_out))\n",
        "\n",
        "        class_out = F.relu(self.class_conv(conv8_out))\n",
        "        pool_out = F.adaptive_avg_pool2d(class_out, 1)\n",
        "        pool_out.squeeze_(-1)\n",
        "        pool_out.squeeze_(-1)\n",
        "        return pool_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqT34WTTv8H1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "def mnist_iid(dataset, num_users):\n",
        "    \"\"\"\n",
        "    Sample I.I.D. client data from MNIST dataset\n",
        "    :param dataset:\n",
        "    :param num_users:\n",
        "    :return: dict of image index\n",
        "    \"\"\"\n",
        "    num_items = int(len(dataset)/num_users)\n",
        "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
        "    for i in range(num_users):\n",
        "        dict_users[i] = set(np.random.choice(all_idxs, num_items,\n",
        "                                             replace=False))\n",
        "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
        "    return dict_users\n",
        "\n",
        "\n",
        "def mnist_noniid(dataset, num_users):\n",
        "    \"\"\"\n",
        "    Sample non-I.I.D client data from MNIST dataset\n",
        "    :param dataset:\n",
        "    :param num_users:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # 60,000 training imgs -->  200 imgs/shard X 300 shards\n",
        "    num_shards, num_imgs = 200, 300\n",
        "    idx_shard = [i for i in range(num_shards)]\n",
        "    dict_users = {i: np.array([]) for i in range(num_users)}\n",
        "    idxs = np.arange(num_shards*num_imgs)\n",
        "    labels = dataset.train_labels.numpy()\n",
        "\n",
        "    # sort labels\n",
        "    idxs_labels = np.vstack((idxs, labels))\n",
        "    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
        "    idxs = idxs_labels[0, :]\n",
        "\n",
        "    # divide and assign 2 shards/client\n",
        "    for i in range(num_users):\n",
        "        rand_set = set(np.random.choice(idx_shard, 2, replace=False))\n",
        "        idx_shard = list(set(idx_shard) - rand_set)\n",
        "        for rand in rand_set:\n",
        "            dict_users[i] = np.concatenate(\n",
        "                (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]), axis=0)\n",
        "    return dict_users\n",
        "\n",
        "\n",
        "def mnist_noniid_unequal(dataset, num_users):\n",
        "    \"\"\"\n",
        "    Sample non-I.I.D client data from MNIST dataset s.t clients\n",
        "    have unequal amount of data\n",
        "    :param dataset:\n",
        "    :param num_users:\n",
        "    :returns a dict of clients with each clients assigned certain\n",
        "    number of training imgs\n",
        "    \"\"\"\n",
        "    # 60,000 training imgs --> 50 imgs/shard X 1200 shards\n",
        "    num_shards, num_imgs = 1200, 50\n",
        "    idx_shard = [i for i in range(num_shards)]\n",
        "    dict_users = {i: np.array([]) for i in range(num_users)}\n",
        "    idxs = np.arange(num_shards*num_imgs)\n",
        "    labels = dataset.train_labels.numpy()\n",
        "\n",
        "    # sort labels\n",
        "    idxs_labels = np.vstack((idxs, labels))\n",
        "    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
        "    idxs = idxs_labels[0, :]\n",
        "\n",
        "    # Minimum and maximum shards assigned per client:\n",
        "    min_shard = 1\n",
        "    max_shard = 30\n",
        "\n",
        "    # Divide the shards into random chunks for every client\n",
        "    # s.t the sum of these chunks = num_shards\n",
        "    random_shard_size = np.random.randint(min_shard, max_shard+1,\n",
        "                                          size=num_users)\n",
        "    random_shard_size = np.around(random_shard_size /\n",
        "                                  sum(random_shard_size) * num_shards)\n",
        "    random_shard_size = random_shard_size.astype(int)\n",
        "\n",
        "    # Assign the shards randomly to each client\n",
        "    if sum(random_shard_size) > num_shards:\n",
        "\n",
        "        for i in range(num_users):\n",
        "            # First assign each client 1 shard to ensure every client has\n",
        "            # atleast one shard of data\n",
        "            rand_set = set(np.random.choice(idx_shard, 1, replace=False))\n",
        "            idx_shard = list(set(idx_shard) - rand_set)\n",
        "            for rand in rand_set:\n",
        "                dict_users[i] = np.concatenate(\n",
        "                    (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]),\n",
        "                    axis=0)\n",
        "\n",
        "        random_shard_size = random_shard_size-1\n",
        "\n",
        "        # Next, randomly assign the remaining shards\n",
        "        for i in range(num_users):\n",
        "            if len(idx_shard) == 0:\n",
        "                continue\n",
        "            shard_size = random_shard_size[i]\n",
        "            if shard_size > len(idx_shard):\n",
        "                shard_size = len(idx_shard)\n",
        "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
        "                                            replace=False))\n",
        "            idx_shard = list(set(idx_shard) - rand_set)\n",
        "            for rand in rand_set:\n",
        "                dict_users[i] = np.concatenate(\n",
        "                    (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]),\n",
        "                    axis=0)\n",
        "    else:\n",
        "\n",
        "        for i in range(num_users):\n",
        "            shard_size = random_shard_size[i]\n",
        "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
        "                                            replace=False))\n",
        "            idx_shard = list(set(idx_shard) - rand_set)\n",
        "            for rand in rand_set:\n",
        "                dict_users[i] = np.concatenate(\n",
        "                    (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]),\n",
        "                    axis=0)\n",
        "\n",
        "        if len(idx_shard) > 0:\n",
        "            # Add the leftover shards to the client with minimum images:\n",
        "            shard_size = len(idx_shard)\n",
        "            # Add the remaining shard to the client with lowest data\n",
        "            k = min(dict_users, key=lambda x: len(dict_users.get(x)))\n",
        "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
        "                                            replace=False))\n",
        "            idx_shard = list(set(idx_shard) - rand_set)\n",
        "            for rand in rand_set:\n",
        "                dict_users[k] = np.concatenate(\n",
        "                    (dict_users[k], idxs[rand*num_imgs:(rand+1)*num_imgs]),\n",
        "                    axis=0)\n",
        "\n",
        "    return dict_users\n",
        "\n",
        "\n",
        "def cifar_iid(dataset, num_users):\n",
        "    \"\"\"\n",
        "    Sample I.I.D. client data from CIFAR10 dataset\n",
        "    :param dataset:\n",
        "    :param num_users:\n",
        "    :return: dict of image index\n",
        "    \"\"\"\n",
        "    num_items = int(len(dataset)/num_users)\n",
        "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
        "    for i in range(num_users):\n",
        "        dict_users[i] = set(np.random.choice(all_idxs, num_items,\n",
        "                                             replace=False))\n",
        "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
        "    return dict_users\n",
        "\n",
        "\n",
        "def cifar_noniid(dataset, num_users):\n",
        "    \"\"\"\n",
        "    Sample non-I.I.D client data from CIFAR10 dataset\n",
        "    :param dataset:\n",
        "    :param num_users:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    num_shards, num_imgs = 200, 250\n",
        "    idx_shard = [i for i in range(num_shards)]\n",
        "    dict_users = {i: np.array([]) for i in range(num_users)}\n",
        "    idxs = np.arange(num_shards*num_imgs)\n",
        "    # labels = dataset.train_labels.numpy()\n",
        "    labels = np.array(dataset.train_labels)\n",
        "\n",
        "    # sort labels\n",
        "    idxs_labels = np.vstack((idxs, labels))\n",
        "    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
        "    idxs = idxs_labels[0, :]\n",
        "\n",
        "    # divide and assign\n",
        "    for i in range(num_users):\n",
        "        rand_set = set(np.random.choice(idx_shard, 2, replace=False))\n",
        "        idx_shard = list(set(idx_shard) - rand_set)\n",
        "        for rand in rand_set:\n",
        "            dict_users[i] = np.concatenate(\n",
        "                (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]), axis=0)\n",
        "    return dict_users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Q8s3zbv_eq"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "# from sampling import mnist_iid, mnist_noniid, mnist_noniid_unequal\n",
        "# from sampling import cifar_iid, cifar_noniid\n",
        "\n",
        "\n",
        "def get_dataset(args):\n",
        "    \"\"\" Returns train and test datasets and a user group which is a dict where\n",
        "    the keys are the user index and the values are the corresponding data for\n",
        "    each of those users.\n",
        "    \"\"\"\n",
        "\n",
        "    if args.dataset == 'cifar':\n",
        "        data_dir = '../data/cifar/'\n",
        "        apply_transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "        train_dataset = datasets.CIFAR10(data_dir, train=True, download=True,\n",
        "                                       transform=apply_transform)\n",
        "\n",
        "        test_dataset = datasets.CIFAR10(data_dir, train=False, download=True,\n",
        "                                      transform=apply_transform)\n",
        "\n",
        "        # sample training data amongst users\n",
        "        if args.iid:\n",
        "            # Sample IID user data from Mnist\n",
        "            user_groups = cifar_iid(train_dataset, args.num_users)\n",
        "        else:\n",
        "            # Sample Non-IID user data from Mnist\n",
        "            if args.unequal:\n",
        "                # Chose uneuqal splits for every user\n",
        "                raise NotImplementedError()\n",
        "            else:\n",
        "                # Chose euqal splits for every user\n",
        "                user_groups = cifar_noniid(train_dataset, args.num_users)\n",
        "\n",
        "    elif args.dataset == 'mnist' or 'fmnist':\n",
        "        if args.dataset == 'mnist':\n",
        "            data_dir = '../data/mnist/'\n",
        "        else:\n",
        "            data_dir = '../data/fmnist/'\n",
        "\n",
        "        apply_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "        train_dataset = datasets.MNIST(data_dir, train=True, download=True,\n",
        "                                       transform=apply_transform)\n",
        "\n",
        "        test_dataset = datasets.MNIST(data_dir, train=False, download=True,\n",
        "                                      transform=apply_transform)\n",
        "\n",
        "        # sample training data amongst users\n",
        "        if args.iid:\n",
        "            # Sample IID user data from Mnist\n",
        "            user_groups = mnist_iid(train_dataset, args.num_users)\n",
        "        else:\n",
        "            # Sample Non-IID user data from Mnist\n",
        "            if args.unequal:\n",
        "                # Chose uneuqal splits for every user\n",
        "                user_groups = mnist_noniid_unequal(train_dataset, args.num_users)\n",
        "            else:\n",
        "                # Chose euqal splits for every user\n",
        "                user_groups = mnist_noniid(train_dataset, args.num_users)\n",
        "\n",
        "    return train_dataset, test_dataset, user_groups\n",
        "\n",
        "\n",
        "def average_weights(w):\n",
        "    \"\"\"\n",
        "    Returns the average of the weights.\n",
        "    \"\"\"\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for key in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[key] += w[i][key]\n",
        "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
        "    return w_avg\n",
        "\n",
        "\n",
        "def exp_details(args):\n",
        "    print('\\nExperimental details:')\n",
        "    print(f'    Model     : {args.model}')\n",
        "    print(f'    Optimizer : {args.optimizer}')\n",
        "    print(f'    Learning  : {args.lr}')\n",
        "    print(f'    Global Rounds   : {args.epochs}\\n')\n",
        "\n",
        "    print('    Federated parameters:')\n",
        "    if args.iid:\n",
        "        print('    IID')\n",
        "    else:\n",
        "        print('    Non-IID')\n",
        "    print(f'    Fraction of users  : {args.frac}')\n",
        "    print(f'    Local Batch size   : {args.local_bs}')\n",
        "    print(f'    Local Epochs       : {args.local_ep}\\n')\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLRVL4wZwCzC"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "# from sampling import mnist_iid, mnist_noniid, mnist_noniid_unequal\n",
        "# from sampling import cifar_iid, cifar_noniid\n",
        "\n",
        "\n",
        "def get_dataset(args):\n",
        "    \"\"\" Returns train and test datasets and a user group which is a dict where\n",
        "    the keys are the user index and the values are the corresponding data for\n",
        "    each of those users.\n",
        "    \"\"\"\n",
        "\n",
        "    if args.dataset == 'cifar':\n",
        "        data_dir = '../data/cifar/'\n",
        "        apply_transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "        train_dataset = datasets.CIFAR10(data_dir, train=True, download=True,\n",
        "                                       transform=apply_transform)\n",
        "\n",
        "        test_dataset = datasets.CIFAR10(data_dir, train=False, download=True,\n",
        "                                      transform=apply_transform)\n",
        "\n",
        "        # sample training data amongst users\n",
        "        if args.iid:\n",
        "            # Sample IID user data from Mnist\n",
        "            user_groups = cifar_iid(train_dataset, args.num_users)\n",
        "        else:\n",
        "            # Sample Non-IID user data from Mnist\n",
        "            if args.unequal:\n",
        "                # Chose uneuqal splits for every user\n",
        "                raise NotImplementedError()\n",
        "            else:\n",
        "                # Chose euqal splits for every user\n",
        "                user_groups = cifar_noniid(train_dataset, args.num_users)\n",
        "\n",
        "    elif args.dataset == 'mnist' or 'fmnist':\n",
        "        if args.dataset == 'mnist':\n",
        "            data_dir = '../data/mnist/'\n",
        "        else:\n",
        "            data_dir = '../data/fmnist/'\n",
        "\n",
        "        apply_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "        train_dataset = datasets.MNIST(data_dir, train=True, download=True,\n",
        "                                       transform=apply_transform)\n",
        "\n",
        "        test_dataset = datasets.MNIST(data_dir, train=False, download=True,\n",
        "                                      transform=apply_transform)\n",
        "\n",
        "        # sample training data amongst users\n",
        "        if args.iid:\n",
        "            # Sample IID user data from Mnist\n",
        "            user_groups = mnist_iid(train_dataset, args.num_users)\n",
        "        else:\n",
        "            # Sample Non-IID user data from Mnist\n",
        "            if args.unequal:\n",
        "                # Chose uneuqal splits for every user\n",
        "                user_groups = mnist_noniid_unequal(train_dataset, args.num_users)\n",
        "            else:\n",
        "                # Chose euqal splits for every user\n",
        "                user_groups = mnist_noniid(train_dataset, args.num_users)\n",
        "\n",
        "    return train_dataset, test_dataset, user_groups\n",
        "\n",
        "\n",
        "def average_weights(w):\n",
        "    \"\"\"\n",
        "    Returns the average of the weights.\n",
        "    \"\"\"\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for key in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[key] += w[i][key]\n",
        "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
        "    return w_avg\n",
        "\n",
        "model = 'mlp'\n",
        "optimizer = 'sgd'\n",
        "lr = 0.01\n",
        "epochs = 10\n",
        "frac = 0.1\n",
        "local_bs = 10 # local batch size\n",
        "local_ep = 10 # the number of local epochs\n",
        "\n",
        "iid = 1\n",
        "\n",
        "def exp_details():\n",
        "    print('\\nExperimental details:')\n",
        "    print(f'    Model     : {model}')\n",
        "    print(f'    Optimizer : {optimizer}')\n",
        "    print(f'    Learning  : {lr}')\n",
        "    print(f'    Global Rounds   : {epochs}\\n')\n",
        "\n",
        "    print('    Federated parameters:')\n",
        "    if iid:\n",
        "        print('    IID')\n",
        "    else:\n",
        "        print('    Non-IID')\n",
        "    print(f'    Fraction of users  : {frac}')\n",
        "    print(f'    Local Batch size   : {local_bs}')\n",
        "    print(f'    Local Epochs       : {local_ep}\\n')\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE014TYnwE0t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "\n",
        "# from options import args_parser\n",
        "# from update import LocalUpdate, test_inference\n",
        "# from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n",
        "# from utils import get_dataset, average_weights, exp_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2_qVAAbwHrn",
        "outputId": "3738c628-facf-4b3a-d609-b807a8251e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "googlespeech\n"
          ]
        }
      ],
      "source": [
        "# %%writefile parsing.py\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Train prototypical networks')\n",
        "# data args\n",
        "default_dataset = 'googlespeech'\n",
        "parser.add_argument('--data.dataset', type=str, default=default_dataset, metavar='DS',\n",
        "                    help=\"data set name (default: {:s})\".format(default_dataset))\n",
        "default_split = 'vinyals'\n",
        "parser.add_argument('--data.split', type=str, default=default_split, metavar='SP',\n",
        "                    help=\"split name (default: {:s})\".format(default_split))\n",
        "parser.add_argument('--data.way', type=int, default=1, metavar='WAY',\n",
        "                    help=\"number of classes per episode (default: 60)\")\n",
        "parser.add_argument('--data.shot', type=int, default=2, metavar='SHOT',\n",
        "                    help=\"number of support examples per class (default: 5)\")\n",
        "parser.add_argument('--data.query', type=int, default=5, metavar='QUERY',\n",
        "                    help=\"number of query examples per class (default: 5)\")\n",
        "parser.add_argument('--data.test_way', type=int, default=1, metavar='TESTWAY',\n",
        "                    help=\"number of classes per episode in test. 0 means same as data.way (default: 5)\")\n",
        "parser.add_argument('--data.test_shot', type=int, default=2, metavar='TESTSHOT',\n",
        "                    help=\"number of support examples per class in test. 0 means same as data.shot (default: 0)\")\n",
        "parser.add_argument('--data.test_query', type=int, default=14, metavar='TESTQUERY',\n",
        "                    help=\"number of query examples per class in test. 0 means same as data.query (default: 15)\")\n",
        "parser.add_argument('--data.train_episodes', type=int, default=100, metavar='NTRAIN',\n",
        "                    help=\"number of train episodes per epoch (default: 100)\")\n",
        "parser.add_argument('--data.test_episodes', type=int, default=100, metavar='NTEST',\n",
        "                    help=\"number of test episodes per epoch (default: 100)\")\n",
        "parser.add_argument('--data.trainval', action='store_true', help=\"run in train+validation mode (default: False)\")\n",
        "parser.add_argument('--data.sequential', action='store_true', help=\"use sequential sampler instead of episodic (default: False)\")\n",
        "parser.add_argument('--data.cuda', action='store_true', help=\"run in CUDA mode (default: False)\")\n",
        "\n",
        "# model args\n",
        "default_model_name = 'protonet_conv'\n",
        "default_encoding = 'C64'\n",
        "parser.add_argument('--model.model_name', type=str, default=default_model_name, metavar='MODELNAME',\n",
        "                    help=\"model name (default: {:s})\".format(default_model_name))\n",
        "parser.add_argument('--model.x_dim', type=str, default='1,51,40', metavar='XDIM',\n",
        "                    help=\"dimensionality of input images (default: '1,28,28')\")\n",
        "parser.add_argument('--model.hid_dim', type=int, default=64, metavar='HIDDIM',\n",
        "                    help=\"dimensionality of hidden layers (default: 64)\")\n",
        "parser.add_argument('--model.z_dim', type=int, default=64, metavar='ZDIM',\n",
        "                    help=\"dimensionality of input images (default: 64)\")\n",
        "parser.add_argument('--model.encoding', type=str, default=default_encoding, metavar='MODELENC',\n",
        "                    help=\"model encoding (default: {:s})\".format(default_encoding))\n",
        "# train args\n",
        "parser.add_argument('--train.epochs', type=int, default=200, metavar='NEPOCHS',\n",
        "                    help='number of epochs to train (default: 10000)')\n",
        "parser.add_argument('--train.optim_method', type=str, default='Adam', metavar='OPTIM',\n",
        "                    help='optimization method (default: Adam)')\n",
        "parser.add_argument('--train.learning_rate', type=float, default=0.001, metavar='LR',\n",
        "                    help='learning rate (default: 0.0001)')\n",
        "parser.add_argument('--train.decay_every', type=int, default=20, metavar='LRDECAY',\n",
        "                    help='number of epochs after which to decay the learning rate')\n",
        "default_weight_decay = 0.0\n",
        "parser.add_argument('--train.weight_decay', type=float, default=default_weight_decay, metavar='WD',\n",
        "                    help=\"weight decay (default: {:f})\".format(default_weight_decay))\n",
        "parser.add_argument('--train.patience', type=int, default=200, metavar='PATIENCE',\n",
        "                    help='number of epochs to wait before validation improvement (default: 1000)')\n",
        "\n",
        "# log args\n",
        "default_fields = 'loss,acc'\n",
        "parser.add_argument('--log.fields', type=str, default=default_fields, metavar='FIELDS',\n",
        "                    help=\"fields to monitor during training (default: {:s})\".format(default_fields))\n",
        "default_exp_dir = 'results'\n",
        "parser.add_argument('--log.exp_dir', type=str, default=default_exp_dir, metavar='EXP_DIR',\n",
        "                    help=\"directory where experiments should be saved (default: {:s})\".format(default_exp_dir))\n",
        "\n",
        "# speech data args\n",
        "parser.add_argument('--speech.include_background', action='store_true', help=\"mix background noise with samples (default: False)\")\n",
        "parser.add_argument('--speech.include_silence', action='store_true', help=\"one of the classes out of n should be silence (default: False)\")\n",
        "parser.add_argument('--speech.include_unknown', action='store_true', help=\"one of the classes out of n should be unknown (default: False)\")\n",
        "parser.add_argument('--speech.sample_rate', type=int, default=16000, help='desired sampling rate of the input')\n",
        "parser.add_argument('--speech.clip_duration', type=int, default=1000, help='clip duration in milliseconds')\n",
        "parser.add_argument('--speech.window_size', type=int, default=40)\n",
        "parser.add_argument('--speech.window_stride', type=int,default=20)\n",
        "parser.add_argument('--speech.num_features', type=int, default=40, help='Number of mfcc features to extract')\n",
        "parser.add_argument('--speech.time_shift', type=int, default=100, help='time shift the audio in milliseconds')\n",
        "parser.add_argument('--speech.bg_volume', type=float, default=0.1, help='background volumen to mix in between 0 and 1')\n",
        "parser.add_argument('--speech.bg_frequency', type=float, default=1.0, help='Amount of samples that should be mixed with background noise (between 0 and 1)')\n",
        "parser.add_argument('--speech.num_silence', type=int, default=1000, help='Number of silence samples to generate')\n",
        "parser.add_argument('--speech.foreground_volume', type=float, default=1)\n",
        "\n",
        "\n",
        "args = vars(parser.parse_args(args=[]))\n",
        "\n",
        "opt = args\n",
        "\n",
        "print(opt['data.dataset'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PpMPyTzwKPE",
        "outputId": "15dd1f85-6f22-4a4f-9b03-e86b79934322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "googlespeech\n"
          ]
        }
      ],
      "source": [
        "# %%writefile parsing.py\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Train prototypical networks')\n",
        "# data args\n",
        "default_dataset = 'googlespeech'\n",
        "parser.add_argument('--data.dataset', type=str, default=default_dataset, metavar='DS',\n",
        "                    help=\"data set name (default: {:s})\".format(default_dataset))\n",
        "default_split = 'vinyals'\n",
        "parser.add_argument('--data.split', type=str, default=default_split, metavar='SP',\n",
        "                    help=\"split name (default: {:s})\".format(default_split))\n",
        "parser.add_argument('--data.way', type=int, default=1, metavar='WAY',\n",
        "                    help=\"number of classes per episode (default: 60)\")\n",
        "parser.add_argument('--data.shot', type=int, default=2, metavar='SHOT',\n",
        "                    help=\"number of support examples per class (default: 5)\")\n",
        "parser.add_argument('--data.query', type=int, default=5, metavar='QUERY',\n",
        "                    help=\"number of query examples per class (default: 5)\")\n",
        "parser.add_argument('--data.test_way', type=int, default=1, metavar='TESTWAY',\n",
        "                    help=\"number of classes per episode in test. 0 means same as data.way (default: 5)\")\n",
        "parser.add_argument('--data.test_shot', type=int, default=2, metavar='TESTSHOT',\n",
        "                    help=\"number of support examples per class in test. 0 means same as data.shot (default: 0)\")\n",
        "parser.add_argument('--data.test_query', type=int, default=14, metavar='TESTQUERY',\n",
        "                    help=\"number of query examples per class in test. 0 means same as data.query (default: 15)\")\n",
        "parser.add_argument('--data.train_episodes', type=int, default=100, metavar='NTRAIN',\n",
        "                    help=\"number of train episodes per epoch (default: 100)\")\n",
        "parser.add_argument('--data.test_episodes', type=int, default=100, metavar='NTEST',\n",
        "                    help=\"number of test episodes per epoch (default: 100)\")\n",
        "parser.add_argument('--data.trainval', action='store_true', help=\"run in train+validation mode (default: False)\")\n",
        "parser.add_argument('--data.sequential', action='store_true', help=\"use sequential sampler instead of episodic (default: False)\")\n",
        "parser.add_argument('--data.cuda', action='store_true', help=\"run in CUDA mode (default: False)\")\n",
        "\n",
        "# model args\n",
        "default_model_name = 'protonet_conv'\n",
        "default_encoding = 'C64'\n",
        "parser.add_argument('--model.model_name', type=str, default=default_model_name, metavar='MODELNAME',\n",
        "                    help=\"model name (default: {:s})\".format(default_model_name))\n",
        "parser.add_argument('--model.x_dim', type=str, default='1,51,40', metavar='XDIM',\n",
        "                    help=\"dimensionality of input images (default: '1,28,28')\")\n",
        "parser.add_argument('--model.hid_dim', type=int, default=64, metavar='HIDDIM',\n",
        "                    help=\"dimensionality of hidden layers (default: 64)\")\n",
        "parser.add_argument('--model.z_dim', type=int, default=64, metavar='ZDIM',\n",
        "                    help=\"dimensionality of input images (default: 64)\")\n",
        "parser.add_argument('--model.encoding', type=str, default=default_encoding, metavar='MODELENC',\n",
        "                    help=\"model encoding (default: {:s})\".format(default_encoding))\n",
        "# train args\n",
        "parser.add_argument('--train.epochs', type=int, default=200, metavar='NEPOCHS',\n",
        "                    help='number of epochs to train (default: 10000)')\n",
        "parser.add_argument('--train.optim_method', type=str, default='Adam', metavar='OPTIM',\n",
        "                    help='optimization method (default: Adam)')\n",
        "parser.add_argument('--train.learning_rate', type=float, default=0.001, metavar='LR',\n",
        "                    help='learning rate (default: 0.0001)')\n",
        "parser.add_argument('--train.decay_every', type=int, default=20, metavar='LRDECAY',\n",
        "                    help='number of epochs after which to decay the learning rate')\n",
        "default_weight_decay = 0.0\n",
        "parser.add_argument('--train.weight_decay', type=float, default=default_weight_decay, metavar='WD',\n",
        "                    help=\"weight decay (default: {:f})\".format(default_weight_decay))\n",
        "parser.add_argument('--train.patience', type=int, default=200, metavar='PATIENCE',\n",
        "                    help='number of epochs to wait before validation improvement (default: 1000)')\n",
        "\n",
        "# log args\n",
        "default_fields = 'loss,acc'\n",
        "parser.add_argument('--log.fields', type=str, default=default_fields, metavar='FIELDS',\n",
        "                    help=\"fields to monitor during training (default: {:s})\".format(default_fields))\n",
        "default_exp_dir = 'results'\n",
        "parser.add_argument('--log.exp_dir', type=str, default=default_exp_dir, metavar='EXP_DIR',\n",
        "                    help=\"directory where experiments should be saved (default: {:s})\".format(default_exp_dir))\n",
        "\n",
        "# speech data args\n",
        "parser.add_argument('--speech.include_background', action='store_true', help=\"mix background noise with samples (default: False)\")\n",
        "parser.add_argument('--speech.include_silence', action='store_true', help=\"one of the classes out of n should be silence (default: False)\")\n",
        "parser.add_argument('--speech.include_unknown', action='store_true', help=\"one of the classes out of n should be unknown (default: False)\")\n",
        "parser.add_argument('--speech.sample_rate', type=int, default=16000, help='desired sampling rate of the input')\n",
        "parser.add_argument('--speech.clip_duration', type=int, default=1000, help='clip duration in milliseconds')\n",
        "parser.add_argument('--speech.window_size', type=int, default=40)\n",
        "parser.add_argument('--speech.window_stride', type=int,default=20)\n",
        "parser.add_argument('--speech.num_features', type=int, default=40, help='Number of mfcc features to extract')\n",
        "parser.add_argument('--speech.time_shift', type=int, default=100, help='time shift the audio in milliseconds')\n",
        "parser.add_argument('--speech.bg_volume', type=float, default=0.1, help='background volumen to mix in between 0 and 1')\n",
        "parser.add_argument('--speech.bg_frequency', type=float, default=1.0, help='Amount of samples that should be mixed with background noise (between 0 and 1)')\n",
        "parser.add_argument('--speech.num_silence', type=int, default=1000, help='Number of silence samples to generate')\n",
        "parser.add_argument('--speech.foreground_volume', type=float, default=1)\n",
        "\n",
        "\n",
        "\n",
        "args = vars(parser.parse_args(args=[]))\n",
        "\n",
        "opt = args\n",
        "\n",
        "print(opt['data.dataset'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZdKgM6owNKt",
        "outputId": "45541c66-df2f-4129-bfec-b5d3347dcd3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "googlespeech\n"
          ]
        }
      ],
      "source": [
        "# %%writefile parsing.py\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Train prototypical networks')\n",
        "# data args\n",
        "default_dataset = 'googlespeech'\n",
        "parser.add_argument('--data.dataset', type=str, default=default_dataset, metavar='DS',\n",
        "                    help=\"data set name (default: {:s})\".format(default_dataset))\n",
        "default_split = 'vinyals'\n",
        "parser.add_argument('--data.split', type=str, default=default_split, metavar='SP',\n",
        "                    help=\"split name (default: {:s})\".format(default_split))\n",
        "parser.add_argument('--data.way', type=int, default=1, metavar='WAY',\n",
        "                    help=\"number of classes per episode (default: 60)\")\n",
        "parser.add_argument('--data.shot', type=int, default=2, metavar='SHOT',\n",
        "                    help=\"number of support examples per class (default: 5)\")\n",
        "parser.add_argument('--data.query', type=int, default=5, metavar='QUERY',\n",
        "                    help=\"number of query examples per class (default: 5)\")\n",
        "parser.add_argument('--data.test_way', type=int, default=1, metavar='TESTWAY',\n",
        "                    help=\"number of classes per episode in test. 0 means same as data.way (default: 5)\")\n",
        "parser.add_argument('--data.test_shot', type=int, default=2, metavar='TESTSHOT',\n",
        "                    help=\"number of support examples per class in test. 0 means same as data.shot (default: 0)\")\n",
        "parser.add_argument('--data.test_query', type=int, default=13, metavar='TESTQUERY',\n",
        "                    help=\"number of query examples per class in test. 0 means same as data.query (default: 15)\")\n",
        "parser.add_argument('--data.train_episodes', type=int, default=100, metavar='NTRAIN',\n",
        "                    help=\"number of train episodes per epoch (default: 100)\")\n",
        "parser.add_argument('--data.test_episodes', type=int, default=100, metavar='NTEST',\n",
        "                    help=\"number of test episodes per epoch (default: 100)\")\n",
        "parser.add_argument('--data.trainval', action='store_true', help=\"run in train+validation mode (default: False)\")\n",
        "parser.add_argument('--data.sequential', action='store_true', help=\"use sequential sampler instead of episodic (default: False)\")\n",
        "parser.add_argument('--data.cuda', action='store_true', help=\"run in CUDA mode (default: False)\")\n",
        "\n",
        "# model args\n",
        "default_model_name = 'protonet_conv'\n",
        "default_encoding = 'C64'\n",
        "parser.add_argument('--model.model_name', type=str, default=default_model_name, metavar='MODELNAME',\n",
        "                    help=\"model name (default: {:s})\".format(default_model_name))\n",
        "parser.add_argument('--model.x_dim', type=str, default=\"1,51,40\", metavar='XDIM',\n",
        "                    help=\"dimensionality of input images (default: '1,28,28')\")\n",
        "parser.add_argument('--model.hid_dim', type=int, default=64, metavar='HIDDIM',\n",
        "                    help=\"dimensionality of hidden layers (default: 64)\")\n",
        "parser.add_argument('--model.z_dim', type=int, default=64, metavar='ZDIM',\n",
        "                    help=\"dimensionality of input images (default: 64)\")\n",
        "parser.add_argument('--model.encoding', type=str, default=default_encoding, metavar='MODELENC',\n",
        "                    help=\"model encoding (default: {:s})\".format(default_encoding))\n",
        "# train args\n",
        "parser.add_argument('--train.epochs', type=int, default=20, metavar='NEPOCHS',\n",
        "                    help='number of epochs to train (default: 10000)')\n",
        "parser.add_argument('--train.optim_method', type=str, default='Adam', metavar='OPTIM',\n",
        "                    help='optimization method (default: Adam)')\n",
        "parser.add_argument('--train.learning_rate', type=float, default=0.001, metavar='LR',\n",
        "                    help='learning rate (default: 0.0001)')\n",
        "parser.add_argument('--train.decay_every', type=int, default=20, metavar='LRDECAY',\n",
        "                    help='number of epochs after which to decay the learning rate')\n",
        "default_weight_decay = 0.0\n",
        "parser.add_argument('--train.weight_decay', type=float, default=default_weight_decay, metavar='WD',\n",
        "                    help=\"weight decay (default: {:f})\".format(default_weight_decay))\n",
        "parser.add_argument('--train.patience', type=int, default=200, metavar='PATIENCE',\n",
        "                    help='number of epochs to wait before validation improvement (default: 1000)')\n",
        "\n",
        "# log args\n",
        "default_fields = 'loss,acc'\n",
        "parser.add_argument('--log.fields', type=str, default=default_fields, metavar='FIELDS',\n",
        "                    help=\"fields to monitor during training (default: {:s})\".format(default_fields))\n",
        "default_exp_dir = 'fewshotspeech/results'\n",
        "parser.add_argument('--log.exp_dir', type=str, default=default_exp_dir, metavar='EXP_DIR',\n",
        "                    help=\"directory where experiments should be saved (default: {:s})\".format(default_exp_dir))\n",
        "\n",
        "# speech data args\n",
        "parser.add_argument('--speech.include_background', action='store_true', help=\"mix background noise with samples (default: False)\")\n",
        "parser.add_argument('--speech.include_silence', action='store_true', help=\"one of the classes out of n should be silence (default: False)\")\n",
        "parser.add_argument('--speech.include_unknown', action='store_true', help=\"one of the classes out of n should be unknown (default: False)\")\n",
        "parser.add_argument('--speech.sample_rate', type=int, default=16000, help='desired sampling rate of the input')\n",
        "parser.add_argument('--speech.clip_duration', type=int, default=1000, help='clip duration in milliseconds')\n",
        "parser.add_argument('--speech.window_size', type=int, default=40)\n",
        "parser.add_argument('--speech.window_stride', type=int,default=20)\n",
        "parser.add_argument('--speech.num_features', type=int, default=40, help='Number of mfcc features to extract')\n",
        "parser.add_argument('--speech.time_shift', type=int, default=100, help='time shift the audio in milliseconds')\n",
        "parser.add_argument('--speech.bg_volume', type=float, default=0.1, help='background volumen to mix in between 0 and 1')\n",
        "parser.add_argument('--speech.bg_frequency', type=float, default=1.0, help='Amount of samples that should be mixed with background noise (between 0 and 1)')\n",
        "parser.add_argument('--speech.num_silence', type=int, default=1000, help='Number of silence samples to generate')\n",
        "parser.add_argument('--speech.foreground_volume', type=float, default=1)\n",
        "\n",
        "#triplet\n",
        "parser.add_argument('--tripletLoss', default=False)\n",
        "\n",
        "args = vars(parser.parse_args(args=[]))\n",
        "\n",
        "opt = args\n",
        "\n",
        "# opt['data.dataset'] = 'coughspeech'\n",
        "\n",
        "print(opt['data.dataset'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPcOMJYfwP2I"
      },
      "outputs": [],
      "source": [
        "opt['data.cuda'] =  True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mf0T9ibwR_O",
        "outputId": "0da59b46-b39a-4912-86f0-f2916fe4ef90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\t       figures\t  protonets.egg-info  results  setup.py\n",
            "fewshotspeech  protonets  requirements.txt    scripts\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nue_tcBKwT16"
      },
      "source": [
        "# Training Fed FrameWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhRkJOe2wUVM",
        "outputId": "776cc22b-a899-4bbe-8b66-6cb744acd6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t       figures\t  protonets.egg-info  results  setup.py\n",
            "fewshotspeech  protonets  requirements.txt    scripts\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/'\n",
        "os.chdir(path)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t6ufI2rwYtd",
        "outputId": "398a91d0-b771-461a-9031-fa25e874eaae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fewshotspeech/results\n"
          ]
        }
      ],
      "source": [
        "# !mkdir '/content/save/'\n",
        "# !mkdir '/content/save/objects/'\n",
        "print(opt['log.exp_dir'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6BJrPE4waR0",
        "outputId": "f747df6a-26d3-4a85-cf26-cbb6885749e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\t       figures\t  protonets.egg-info  results  setup.py\n",
            "fewshotspeech  protonets  requirements.txt    scripts\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI70d4vnwccT"
      },
      "outputs": [],
      "source": [
        "list_train_label = [\n",
        "    'barkingcough',\n",
        "    'chestyandwetcough',\n",
        "    'springallergycoughing',\n",
        "    'coughingupcrapagain',\n",
        "    'dryafternooncough',\n",
        "    'gaggywetcough',\n",
        "    'heavycoldandsorethroatcoughing',\n",
        "    'nightwetcough',\n",
        "]\n",
        "\n",
        "with open('/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/data/speech_commands/core/train.txt','r+') as myfile:\n",
        "    data = myfile.read()\n",
        "    myfile.seek(0)\n",
        "    for train_label in list_train_label:\n",
        "        myfile.write(train_label + '\\n')\n",
        "    # myfile.write('\\n')\n",
        "    myfile.truncate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW5vdnXYwepP"
      },
      "outputs": [],
      "source": [
        "list_val_label = [\n",
        "    'whoopingcough',\n",
        "    'unknow'\n",
        "]\n",
        "\n",
        "with open('/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/data/speech_commands/core/val.txt','r+') as myfile:\n",
        "    data = myfile.read()\n",
        "    myfile.seek(0)\n",
        "    for val_label in list_val_label:\n",
        "        myfile.write(val_label + '\\n')\n",
        "    # myfile.write('\\n')\n",
        "    myfile.truncate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_U3GAXACGKF",
        "outputId": "895c5c6a-cdc1-41a4-e397-23bc8025e47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whoopingcough\n",
            "unknow\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smMn4Cv9LKhd"
      },
      "outputs": [],
      "source": [
        "# import protonets.data\n",
        "# import os\n",
        "# from protonets.data.FewShotSpeechData import FewShotSpeechDataset\n",
        "# import torch\n",
        "# from protonets.utils import filter_opt\n",
        "# from protonets.data.base import EpisodicBatchSampler, SequentialBatchSampler, EpisodicSpeechBatchSampler\n",
        "\n",
        "# def load(opt, splits):\n",
        "#     if opt['data.dataset'] in ['googlespeech']:\n",
        "#         ds = loader(opt, splits)\n",
        "#     else:\n",
        "#         raise ValueError(\"Unknown dataset: {:s}\".format(opt['data.dataset']))\n",
        "\n",
        "#     return ds\n",
        "\n",
        "# def loader(opt, splits):\n",
        "\n",
        "#     ret = { }\n",
        "#     for split in splits:\n",
        "#         if split in ['val', 'test'] and opt['data.test_way'] != 0:\n",
        "#             n_way = opt['data.test_way']\n",
        "#         else:\n",
        "#             n_way = opt['data.way']\n",
        "\n",
        "#         if split in ['val', 'test'] and opt['data.test_shot'] != 0:\n",
        "#             n_support = opt['data.test_shot']\n",
        "#         else:\n",
        "#             n_support = opt['data.shot']\n",
        "\n",
        "#         if split in ['val', 'test'] and opt['data.test_query'] != 0:\n",
        "#             n_query = opt['data.test_query']\n",
        "#         else:\n",
        "#             n_query = opt['data.query']\n",
        "\n",
        "#         if split in ['val', 'test']:\n",
        "#             n_episodes = opt['data.test_episodes']\n",
        "#         else:\n",
        "#             n_episodes = opt['data.train_episodes']\n",
        "\n",
        "#         if opt['data.dataset'] == 'googlespeech':\n",
        "#             speech_args = filter_opt(opt, 'speech')\n",
        "#             # data_dir = os.path.join(os.path.dirname(__file__), '../../data/speech_commands/core')\n",
        "#             data_dir = []\n",
        "#             for i in range(1, 6):\n",
        "#               path = \"/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set\" + str(i)\n",
        "#               data_dir.append(os.path.join(os.path.dirname(__file__), path))\n",
        "#             class_file = os.path.join(os.path.dirname(__file__), '../../data/speech_commands/core', split + '.txt')\n",
        "#             ds = []\n",
        "#             for i in range(5):\n",
        "#               ds.append(FewShotSpeechDataset(data_dir[i], class_file, n_support, n_query, opt['data.cuda'], speech_args))        \n",
        "        \n",
        "#         if opt['data.sequential']:\n",
        "#             sampler = SequentialBatchSampler(len(ds))\n",
        "#         else:\n",
        "          \n",
        "#             sampler = EpisodicSpeechBatchSampler(len(ds), n_way, n_episodes,\n",
        "#                 include_silence=opt['speech.include_silence'],\n",
        "#                 include_unknown=opt['speech.include_unknown'])\n",
        "\n",
        "#         # use num_workers=0, otherwise may receive duplicate episodes\n",
        "#         #Ngan\n",
        "#         ret[split] = []\n",
        "#         for i in range(5): # 5 users\n",
        "#           ret[split].append(torch.utils.data.DataLoader(ds[i], batch_sampler=sampler, num_workers=0))\n",
        "\n",
        "#     return ret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCYaVJt8v6Ba",
        "outputId": "ecb030c5-09f5-4b7f-9d16-a8bb2e8705e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spafe in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install spafe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIXCALEyBSlM",
        "outputId": "d3c164a6-fb12-417a-d9d0-44515f788bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7tpbyfonnMo",
        "outputId": "b7d7a7c3-17ed-4a0d-a588-64f4fc238560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "opt['tripletLoss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mhbvhob0wk6f",
        "outputId": "62231010-f464-4561-8712-48426d839c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "\n",
            "Experimental details:\n",
            "    Model     : mlp\n",
            "    Optimizer : sgd\n",
            "    Learning  : 0.01\n",
            "    Global Rounds   : 10\n",
            "\n",
            "    Federated parameters:\n",
            "    IID\n",
            "    Fraction of users  : 0.1\n",
            "    Local Batch size   : 10\n",
            "    Local Epochs       : 10\n",
            "\n",
            "/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed/few-shot-ho/protonets/utils/../../data/speech_commands/core/train.txt\n",
            "['/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set1', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set2', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set3', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set4', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set5']\n",
            "/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed/few-shot-ho/protonets/utils/../../data/speech_commands/core/val.txt\n",
            "['/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set1', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set2', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set3', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set4', '/content/drive/MyDrive/cough_detection/cough_data/train_test_split/train/set5']\n",
            "ret: [<torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0110>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0190>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0210>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0290>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0310>]\n",
            "{'train': [<torch.utils.data.dataloader.DataLoader object at 0x7fbe11156610>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe11156710>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111563d0>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe11156890>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe11156990>], 'val': [<torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0110>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0190>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0210>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0290>, <torch.utils.data.dataloader.DataLoader object at 0x7fbe111c0310>]}\n",
            "Protonet(\n",
            "  (encoder): ResNet(\n",
            "    (stem): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2dSame(64, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2dSame(64, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2dSame(64, 128, kernel_size=(7, 1), stride=(2, 2))\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2dSame(128, 128, kernel_size=(7, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2dSame(128, 256, kernel_size=(7, 1), stride=(2, 2))\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2dSame(256, 256, kernel_size=(7, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2dSame(256, 512, kernel_size=(7, 1), stride=(2, 2))\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2dSame(512, 512, kernel_size=(7, 1), stride=(1, 1))\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (ca): ChannelAttention(\n",
            "          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (conv1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "          (conv2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "        (sa): SpatialAttention(\n",
            "          (conv1): Conv2d(2, 1, kernel_size=(7, 1), stride=(1, 1), padding=same)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (fc): Linear(in_features=512, out_features=48, bias=True)\n",
            "  )\n",
            ")\n",
            "10\n",
            "5\n",
            "<class 'protonets.models.few_shot.Protonet'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " | Global Training Round : 1 |\n",
            "\n",
            "idxs_users [0, 1, 2, 3, 4]\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 1 train:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed/few-shot-ho/protonets/models/encoder/ResNet18_Attention_kernel_v2.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = F.softmax(out)\n",
            "\n",
            "Epoch 1 train:   0%|          | 1/200 [00:01<05:43,  1.73s/it]\u001b[A\n",
            "Epoch 1 train:   1%|          | 2/200 [00:03<05:13,  1.59s/it]\u001b[A\n",
            "Epoch 1 train:   2%|▏         | 3/200 [00:04<04:15,  1.30s/it]\u001b[A\n",
            "Epoch 1 train:   2%|▏         | 4/200 [00:04<03:33,  1.09s/it]\u001b[A\n",
            "Epoch 1 train:   2%|▎         | 5/200 [00:06<03:37,  1.11s/it]\u001b[A\n",
            "Epoch 1 train:   4%|▎         | 7/200 [00:07<02:34,  1.25it/s]\u001b[A\n",
            "Epoch 1 train:   4%|▍         | 8/200 [00:07<02:32,  1.26it/s]\u001b[A\n",
            "Epoch 1 train:   5%|▌         | 10/200 [00:08<02:32,  1.24it/s]\n",
            "  0%|          | 0/10 [00:08<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c47f4b933c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 val_loader=test_dataset[idx])\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mlocal_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mlocal_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed/few-shot-ho/scripts/train/few_shot/train.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(opt, model, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    117\u001b[0m         optim_config = { 'lr': opt['train.learning_rate'],\n\u001b[1;32m    118\u001b[0m                         'weight_decay': opt['train.weight_decay'] },\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mmax_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train.epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/.shortcut-targets-by-id/1NteBF5MRXaaLPpxUttf7LzJMgH7fgDcx/cough_detection/few-shot-fed/few-shot-ho/protonets/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'on_backward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import protonets.utils.data as data_utils\n",
        "import protonets.utils.model as model_utils\n",
        "import scripts.train.few_shot.train as model_train\n",
        "# model_train.reload(functions.readfunctions)\n",
        "\n",
        "\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# from options import args_parser\n",
        "# from update import LocalUpdate, test_inference\n",
        "# from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n",
        "# from utils import get_dataset, average_weights, exp_details\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    # define paths\n",
        "    path_project = os.path.abspath('..')\n",
        "    logger = SummaryWriter('../logs')\n",
        "    # opt['data.cuda'] =  True\n",
        "    # opt['data.way'] =  2\n",
        "    # opt['data.shot'] =  1\n",
        "    # opt['data.query'] =  12\n",
        "    # opt['data.test_way'] =  2\n",
        "    # opt['data.test_shot'] =  1\n",
        "    # opt['data.test_query'] =  12\n",
        "    # opt['data.train_episodes'] =  200\n",
        "    # opt['data.test_episodes'] =  100\n",
        "    # opt['model.hid_dim'] =  64\n",
        "    # opt['model.z_dim'] =  64\n",
        "    # opt['train.optim_method']='Adam'\n",
        "    # opt['train.learning_rate']=0.001\n",
        "    # opt['train.decay_every']=20\n",
        "    # opt['train.weight_decay']=0.0\n",
        "    opt['data.cuda'] =  True\n",
        "    opt['data.way'] =  2\n",
        "    opt['data.shot'] =  2\n",
        "    opt['data.query'] =  5\n",
        "    opt['data.test_way'] =  2\n",
        "    opt['data.test_shot'] =  2\n",
        "    opt['data.query'] =  12\n",
        "    opt['data.test_query'] =  13\n",
        "    opt['data.train_episodes'] =  200\n",
        "    opt['data.test_episodes'] =  100\n",
        "    opt['model.hid_dim'] =  64\n",
        "    opt['model.z_dim'] =  64\n",
        "    opt['train.optim_method']='Adam'\n",
        "    opt['train.learning_rate']=0.001\n",
        "    opt['train.decay_every']=20\n",
        "    opt['train.weight_decay']=1e-5\n",
        "    # opt['train.patience']=200\n",
        "    # opt['log.exp_dir']=4\n",
        "    # opt['model.encoding']='TCResNet8Dilated'\n",
        "    # opt['model.encoding']='CNN_BiLSTM'\n",
        "    # opt['model.encoding']='Triplet'\n",
        "    # opt['model.encoding']='Attention'\n",
        "    opt['model.encoding']='Attention_kernel_v2'\n",
        "    # opt['model.encoding']='Attention_dilation_v2'\n",
        "    # opt['model.encoding']='Attention_kernel_dilation_v2'\n",
        "    opt['speech.include_unknown']= False\n",
        "    opt['speech.include_background']= False\n",
        "    # for ws in range(40, 88, 2):\n",
        "    opt['speech.window_size'] = 128 #-> 500\n",
        "    opt['speech.window_stride'] = 128/2 #-> 400\n",
        "    print(opt['speech.window_size'])\n",
        "    # opt['tripletLoss'] = True\n",
        "    # print(opt['tripletLoss'])\n",
        "\n",
        "    args = args_parser()\n",
        "    exp_details()\n",
        "\n",
        "    if args.gpu:\n",
        "        torch.cuda.set_device(int(args.gpu))\n",
        "    device = 'cuda' if args.gpu else 'cpu'\n",
        "\n",
        "    opt['data.trainval'] = False\n",
        "    \n",
        "\n",
        "    # load dataset and user groups\n",
        "    if opt['data.trainval']:\n",
        "        data = data_utils.load(opt, ['trainval'])\n",
        "        train_dataset = data['trainval']\n",
        "        test_dataset = None\n",
        "    else:\n",
        "        data = data_utils.load(opt, ['train', 'val'])\n",
        "        # print(\"data\", data)\n",
        "        train_dataset = data['train']\n",
        "        test_dataset = data['val']\n",
        "        # print(test_dataset)\n",
        "\n",
        "    # i = (test_dataset[1])\n",
        "    # print(i)\n",
        "\n",
        "    # BUILD MODEL\n",
        "    opt['model.x_dim'] = 1,51,40 #mfcc FIRST #40ms -20ms\n",
        "    opt['model.x_dim'] = 1,16,40 # ws = 128ms - 64ms\n",
        "    # opt['model.x_dim'] = 1,3,40 # ws = 500ms - 400ms\n",
        "    # opt['model.x_dim'] = 1, 63, 40 #mfcc second ws = 64ms - 32ms\n",
        "    # # opt['model.x_dim'] = 1,13,98 #gfcc\n",
        "    # opt['model.x_dim'] = 1,81,40 #lfcc\n",
        "    # opt['model.x_dim'] = 1,16,256 #CNN-Bi 1CONV\n",
        "    # opt['model.x_dim'] = 1,81,40 #CNN-BI 2CONV\n",
        "    global_model = model_utils.load(opt)\n",
        "\n",
        "    # Set the model to train and send it to device.\n",
        "    global_model.to(device)\n",
        "    global_model.train()\n",
        "    if opt['data.cuda']:\n",
        "        global_model.cuda()\n",
        "    print(global_model)\n",
        "\n",
        "    # copy weights\n",
        "    global_weights = global_model.state_dict()\n",
        "\n",
        "    # Training\n",
        "    opt['log.fields'] = ['acc','loss']\n",
        "    train_loss, train_accuracy = [], []\n",
        "    val_acc_list, net_list = [], []\n",
        "    cv_loss, cv_acc = [], []\n",
        "    print_every = 2\n",
        "    val_loss_pre, counter = 0, 0\n",
        "\n",
        "    print(args.epochs)\n",
        "    print(args.num_users)\n",
        "\n",
        "    print(type(global_model))\n",
        "    print(type(train_dataset))\n",
        "    print(type(test_dataset))\n",
        "\n",
        "    for epoch in tqdm(range(args.epochs)):\n",
        "        local_weights, local_losses = [], []\n",
        "        print(f'\\n | Global Training Round : {epoch+1} |\\n')\n",
        "\n",
        "        global_model.train()\n",
        "        m = max(int(args.frac * args.num_users), 1)\n",
        "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
        "        idxs_users = [0]\n",
        "        idxs_users = [0, 1, 2, 3, 4]\n",
        "        print('idxs_users', idxs_users)\n",
        "        # print(idxs_users)\n",
        "\n",
        "        for idx in idxs_users:\n",
        "            print(idx)\n",
        "\n",
        "            # local_model = LocalUpdate()\n",
        "            w, acc_train, loss, acc_val, loss_val = model_train.update_weights(\n",
        "                opt, \n",
        "                model=copy.deepcopy(global_model), \n",
        "                train_loader=train_dataset[idx], \n",
        "                val_loader=test_dataset[idx])\n",
        "            local_weights.append(copy.deepcopy(w))\n",
        "            local_losses.append(copy.deepcopy(loss))\n",
        "\n",
        "        # update global weights\n",
        "        global_weights = average_weights(local_weights)\n",
        "\n",
        "        # update global weights\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        loss_avg = sum(local_losses) / len(local_losses)\n",
        "        train_loss.append(loss_avg)\n",
        "        print(loss_avg)\n",
        "\n",
        "    #     # Calculate avg training accuracy over all users at every epoch\n",
        "    #     list_acc, list_loss = [], []\n",
        "    #     global_model.eval()\n",
        "    #     for c in range(args.num_users):\n",
        "    #         local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
        "    #                                   idxs=user_groups[idx], logger=logger)\n",
        "    #         acc, loss = local_model.inference(model=global_model)\n",
        "    #         list_acc.append(acc)\n",
        "    #         list_loss.append(loss)\n",
        "    #     train_accuracy.append(sum(list_acc)/len(list_acc))\n",
        "\n",
        "    #     # print global training loss after every 'i' rounds\n",
        "    #     if (epoch+1) % print_every == 0:\n",
        "    #         print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
        "    #         print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
        "    #         print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
        "\n",
        "    # # Test inference after completion of training\n",
        "    # test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
        "\n",
        "    # print(f' \\n Results after {args.epochs} global rounds of training:')\n",
        "    # print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
        "    # print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
        "\n",
        "    # # Saving the objects train_loss and train_accuracy:\n",
        "    # file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
        "    #     format(args.dataset, args.model, args.epochs, args.frac, args.iid,\n",
        "    #            args.local_ep, args.local_bs)\n",
        "\n",
        "    # with open(file_name, 'wb') as f:\n",
        "    #     pickle.dump([train_loss, train_accuracy], f)\n",
        "\n",
        "    # print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n",
        "\n",
        "    ######################################\n",
        "\n",
        "    # PLOTTING (optional)\n",
        "    # import matplotlib\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # matplotlib.use('Agg')\n",
        "\n",
        "    # Plot Loss curve\n",
        "    # plt.figure()\n",
        "    # plt.title('Training Loss vs Communication rounds')\n",
        "    # plt.plot(range(len(train_loss)), train_loss, color='r')\n",
        "    # plt.ylabel('Training loss')\n",
        "    # plt.xlabel('Communication Rounds')\n",
        "    # plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_loss.png'.\n",
        "    #             format(args.dataset, args.model, args.epochs, args.frac,\n",
        "    #                    args.iid, args.local_ep, args.local_bs))\n",
        "    #\n",
        "    # # Plot Average Accuracy vs Communication rounds\n",
        "    # plt.figure()\n",
        "    # plt.title('Average Accuracy vs Communication rounds')\n",
        "    # plt.plot(range(len(train_accuracy)), train_accuracy, color='k')\n",
        "    # plt.ylabel('Average Accuracy')\n",
        "    # plt.xlabel('Communication Rounds')\n",
        "    # plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_acc.png'.\n",
        "    #             format(args.dataset, args.model, args.epochs, args.frac,\n",
        "    #                    args.iid, args.local_ep, args.local_bs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyCyXhaC-HJr"
      },
      "outputs": [],
      "source": [
        "print(\"ok2205\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTgcKXHlubtU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "m = max(int(0.1 * 5), 1)\n",
        "idxs_users = np.random.choice(range(5), m, replace=False)\n",
        "print(m)\n",
        "print(idxs_users)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdiJAlV9Ry5f"
      },
      "source": [
        "Output.shape TResNet = (28, 48)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIUtW2mIHzQC"
      },
      "outputs": [],
      "source": [
        "print(\"ok\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APsmxhRgTmVK",
        "outputId": "d97c1faa-0016-47cf-9c6a-f26c5542345c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJXw84LHIp8x"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from spafe.utils import vis\n",
        "from spafe.features.gfcc import gfcc\n",
        "\n",
        "# init input vars\n",
        "num_ceps = 13\n",
        "low_freq = 0\n",
        "high_freq = 2000\n",
        "nfilts = 24\n",
        "nfft = 512\n",
        "dct_type = 2,\n",
        "use_energy = False,\n",
        "lifter = 5\n",
        "normalize = False\n",
        "    \n",
        "# read wav \n",
        "fs, sig = scipy.io.wavfile.read(\"/content/drive/MyDrive/cough_detection/few-shot-fed/few-shot-ho/data/speech_commands/core/cat/012c8314.wav\")\n",
        "print(sig.shape)\n",
        "# compute features\n",
        "print(fs)\n",
        "gfccs = gfcc(sig=sig,\n",
        "             fs=fs,\n",
        "             num_ceps=num_ceps,\n",
        "             nfilts=nfilts,\n",
        "             nfft=nfft,\n",
        "             low_freq=low_freq,\n",
        "             high_freq=high_freq\n",
        "             \n",
        "             )\n",
        "print(gfccs.shape)\n",
        "# visualize spectogram\n",
        "vis.spectogram(sig, fs)\n",
        "# visualize features\n",
        "vis.visualize_features(gfccs, 'GFCC Index', 'Frame Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NtqDTD9CTgL"
      },
      "outputs": [],
      "source": [
        "import scipy.io.wavfile"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Few-shot-Cough.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}